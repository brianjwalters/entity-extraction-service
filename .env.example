# ===============================================================================
# Entity Extraction Service Configuration - EXAMPLE TEMPLATE
# ===============================================================================
# Copy this file to .env and replace placeholder values
# Last Updated: 2025-10-14 (Phase 4 Cleanup)
# ===============================================================================

# ===============================================================================
# 1. SERVICE CONFIGURATION (10 variables)
# ===============================================================================
PORT=8007                                    # Service port
HOST=0.0.0.0                                 # Bind to all interfaces
ENVIRONMENT=production                        # Environment mode (development|staging|production)
SERVICE_NAME=entity-extraction-service        # Service identifier
SERVICE_URL=http://YOUR_SERVER_IP:8007       # Service URL for external calls
DEBUG_MODE=false                             # Debug mode (true|false)
LOG_LEVEL=INFO                               # Logging verbosity (DEBUG|INFO|WARNING|ERROR)
DEBUG=false                                  # Debug flag for internal operations
SECRET_KEY=change-me-in-production           # Secret key for security operations (MUST CHANGE)
ENABLE_RATE_LIMITING=true                    # Enable request rate limiting
RATE_LIMIT_REQUESTS=100                      # Maximum requests per time window
MAX_REQUEST_SIZE=10485760                    # Maximum request size in bytes (10MB)

# ===============================================================================
# 1A. LOGGING CONFIGURATION (14 variables)
# ===============================================================================
LOGGING__ENABLE_STRUCTURED_LOGGING=true      # Enable structured JSON logging
LOGGING__LOG_FORMAT=json                     # Log format (json|text)
LOGGING__LOG_EXTRACTION_DETAILS=true         # Log detailed extraction information
LOGGING__LOG_PATTERN_MATCHING=false          # Log pattern matching details (verbose, use for debugging)
LOGGING__LOG_AI_REQUESTS=true                # Log AI service requests and responses
LOGGING__LOG_PERFORMANCE_METRICS=true        # Log performance metrics and timing
LOGGING__ENABLE_REQUEST_ID_LOGGING=true      # Enable request ID tracking across services
LOGGING__LOG_REQUEST_BODY=false              # Log request bodies (privacy concern, disable in production)
LOGGING__LOG_RESPONSE_BODY=false             # Log response bodies (privacy concern, disable in production)
LOGGING__ENABLE_FILE_LOGGING=true            # Enable file-based logging
LOGGING__LOG_FILE_PATH=logs/entity-extraction.log  # Log file path (relative to service root)
LOGGING__LOG_ROTATION_SIZE_MB=100            # Log rotation size in megabytes
LOGGING__LOG_RETENTION_DAYS=30               # Log retention period in days
LOGGING__LOG_LEVEL_OVERRIDE=                 # Override log level for specific modules (optional)

# ===============================================================================
# 2. DATABASE - SUPABASE (6 variables)
# ===============================================================================
SUPABASE_URL=https://YOUR_PROJECT_ID.supabase.co  # Supabase project URL
SUPABASE_KEY=YOUR_ANON_KEY_HERE              # Anon key for client operations (REQUIRED)
SUPABASE_API_KEY=YOUR_ANON_KEY_HERE          # API key for authenticated requests (REQUIRED)
SUPABASE_SERVICE_KEY=YOUR_SERVICE_ROLE_KEY_HERE  # Service role key for admin operations (REQUIRED)
STORE_EXTRACTION_RESULTS=true                # Store extraction results in database
EXTRACTION_RETENTION_DAYS=30                 # Retention period for extraction results in days

# ===============================================================================
# 3. vLLM DIRECT INTEGRATION (6 variables)
# ===============================================================================
AI_EXTRACTION_ENABLED=true                   # Enable AI-enhanced extraction
AI_EXTRACTION_USE_VLLM=true                  # Use vLLM for AI operations
VLLM_URL=http://YOUR_SERVER_IP:8080          # vLLM service base URL
AI_EXTRACTION_VLLM_URL=http://YOUR_SERVER_IP:8080/v1  # vLLM API endpoint
AI_EXTRACTION_MODEL_NAME=qwen-instruct-160k        # Model name for AI extraction
AI_EXTRACTION_TIMEOUT=2700                   # AI extraction timeout (seconds)

# ===============================================================================
# 4. CORE EXTRACTION SETTINGS (10 variables)
# ===============================================================================
EXTRACTION_DEFAULT_MODE=ai_enhanced          # Default extraction mode (regex|ai_enhanced|hybrid)
EXTRACTION_FALLBACK_MODE=regex               # Fallback mode when primary fails
EXTRACTION_CONFIDENCE_THRESHOLD=0.7          # Minimum confidence for entity acceptance (0.0-1.0)
EXTRACTION_MIN_CONFIDENCE_REGEX=0.6          # Regex mode confidence threshold
EXTRACTION_MIN_CONFIDENCE_AI=0.8             # AI mode confidence threshold
NO_ENTITY_LIMIT=true                         # No limit on entities for GraphRAG
EXTRACTION_TIMEOUT=2700                      # Overall extraction timeout (seconds)
EXTRACTION_MIN_ENTITY_LENGTH=3               # Minimum entity text length
EXTRACTION_MAX_ENTITY_LENGTH=500             # Maximum entity text length
EXTRACTION_PATTERN_DIR=/srv/luris/be/entity-extraction-service/src/patterns  # Pattern files location

# ===============================================================================
# 5. CHUNKING CONFIGURATION (15 variables) - INTERNAL CHUNKING ONLY
# ===============================================================================
# Internal chunking settings used when service needs to chunk documents
SMART_CHUNK_ENABLED=true                     # Enable smart chunking
SMART_CHUNK_MIN_SIZE=100                     # Minimum chunk size (characters)
SMART_CHUNK_MAX_SIZE=5000                    # Maximum chunk size (characters)
SMART_CHUNK_TARGET_SIZE=1500                 # Target chunk size (characters)
SMART_CHUNK_OVERLAP_SIZE=1000                # Overlap between chunks (characters)
SMART_CHUNK_OVERLAP_PERCENTAGE=0.20          # Overlap as percentage (0.0-1.0)
SMART_CHUNK_PRESERVE_BOUNDARIES=true         # Respect document boundaries
SMART_CHUNK_USE_SEMANTIC_SPLITTING=true      # Use semantic analysis for splits
SMART_CHUNK_RESPECT_HEADERS=true             # Preserve header structures
SMART_CHUNK_RESPECT_SENTENCES=true           # Avoid mid-sentence splits
SMART_CHUNK_RESPECT_PARAGRAPHS=true          # Preserve paragraph structures
SMART_CHUNK_THRESHOLD=500000                 # Threshold for triggering chunking
CHUNKING_BYPASS=true                         # Bypass external chunking service
FORCE_UNIFIED_PROCESSING=true                # Force unified document processing
DISABLE_MICRO_CHUNKING=true                  # Disable micro-chunking

# ===============================================================================
# 6. SERVICE URLs (7 variables) - NO CHUNKING_SERVICE_URL
# ===============================================================================
LOG_SERVICE_URL=http://YOUR_SERVER_IP:8001       # Centralized logging service
PROMPT_SERVICE_URL=http://YOUR_SERVER_IP:8003    # Prompt management service
DOCUMENT_UPLOAD_SERVICE_URL=http://YOUR_SERVER_IP:8008  # Document upload service
GRAPHRAG_SERVICE_URL=http://YOUR_SERVER_IP:8010  # GraphRAG knowledge graph service
DOCUMENT_PROCESSING_SERVICE_URL=http://YOUR_SERVER_IP:8000  # Main document orchestrator
WEBSOCKET_SERVICE_URL=http://YOUR_SERVER_IP:8085  # Real-time WebSocket service
WEBSOCKET_NOTIFICATIONS_ENABLED=true         # Enable WebSocket notifications

# ===============================================================================
# 7. PERFORMANCE & RESOURCE MANAGEMENT (6 variables)
# ===============================================================================
MAX_CONCURRENT_EXTRACTIONS=10                # Maximum parallel extractions
MAX_DOCUMENT_SIZE=52428800                   # Maximum document size in bytes (50MB)
MAX_PROCESSING_TIME=2700                     # Maximum processing time in seconds (45 minutes)
CACHE_ENABLED=true                           # Enable result caching
CACHE_TTL_EXTRACTION=3600                    # Cache TTL for extractions in seconds (1 hour)
METRICS_ENABLED=true                         # Enable performance metrics

# ===============================================================================
# 8. SECURITY (3 variables)
# ===============================================================================
JWT_SECRET=your-secure-jwt-secret-change-this-in-production  # JWT signing secret
JWT_ALGORITHM=HS256                          # JWT algorithm (HS256|RS256)
API_KEY_REQUIRED=false                       # API key enforcement (true|false)

# ===============================================================================
# 9. vLLM ADVANCED CONFIGURATION (30 variables)
# ===============================================================================
# Direct API Configuration (from src/vllm/client.py, models.py, factory.py)
# NOTE: These settings control vLLM's internal behavior and model optimization
VLLM_MODEL=qwen-instruct-160k                      # Model name for vLLM (IBM Granite 3.3 2B with 128K context)
VLLM_MAX_MODEL_LEN=131072                    # Maximum context length in tokens (128K = 131072)
VLLM_GPU_MEMORY_UTILIZATION=0.85             # GPU memory fraction to use (0.0-1.0, recommended: 0.85)
VLLM_SEED=42                                 # Random seed for reproducibility (set to same value across runs)
VLLM_DEFAULT_TEMPERATURE=0.0                 # Default temperature (0.0 = deterministic, 1.0 = creative)
VLLM_DEFAULT_TOP_P=0.95                      # Default top-p nucleus sampling (0.0-1.0)
VLLM_DEFAULT_TOP_K=40                        # Default top-k sampling (number of top tokens to consider)
VLLM_DEFAULT_MAX_TOKENS=4096                 # Default maximum output tokens per request
VLLM_DEFAULT_REPETITION_PENALTY=1.0          # Default repetition penalty (1.0 = no penalty, >1.0 = discourage repetition)

# Performance Optimization (from src/vllm/models.py)
# NOTE: These settings optimize vLLM throughput and memory usage
VLLM_ENABLE_PREFIX_CACHING=true              # Enable KV cache prefix caching (recommended for legal docs)
VLLM_ENABLE_CHUNKED_PREFILL=true             # Enable chunked prefill for better memory management
VLLM_MAX_NUM_BATCHED_TOKENS=8192             # Maximum tokens to batch together (higher = better throughput)
VLLM_MAX_NUM_SEQS=256                        # Maximum sequences to process in parallel
VLLM_BLOCK_SIZE=16                           # KV cache block size (affects memory granularity)
VLLM_SWAP_SPACE=4                            # CPU swap space in GB (for overflow handling)
VLLM_ENFORCE_EAGER=false                     # Disable CUDA graphs (set true for debugging)

# GPU Configuration (from src/vllm/gpu_monitor.py)
# NOTE: GPU monitoring and resource management
VLLM_GPU_ID=0                                # GPU device ID (0-based, check with nvidia-smi)
VLLM_GPU_MEMORY_THRESHOLD=0.90               # GPU memory warning threshold (0.0-1.0)
VLLM_ENABLE_GPU_MONITORING=true              # Enable GPU monitoring and logging
VLLM_GPU_MONITOR_INTERVAL=30                 # GPU monitoring interval in seconds

# HTTP Client Configuration (from src/vllm/client.py)
# NOTE: Settings for HTTPVLLMClient (fallback mode)
VLLM_HTTP_TIMEOUT=300                        # HTTP request timeout in seconds (5 minutes)
VLLM_HTTP_MAX_RETRIES=3                      # Maximum retry attempts for failed requests
VLLM_HTTP_RETRY_DELAY=1.0                    # Retry delay in seconds (exponential backoff)
VLLM_HTTP_CONNECT_TIMEOUT=10                 # Connection timeout in seconds

# Token Estimation (from src/vllm/token_estimator.py)
# NOTE: Token counting and throughput estimation
VLLM_CHARS_PER_TOKEN=4.0                     # Average characters per token (for estimation)
VLLM_TOKEN_OVERLAP_PERCENT=0.1               # Token overlap percentage for chunking (0.0-1.0)
VLLM_PREFILL_RATE=19000                      # Prefill tokens/second (GPU-dependent, measured empirically)
VLLM_DECODE_RATE=150                         # Decode tokens/second (GPU-dependent, measured empirically)

# Warmup Configuration (from src/vllm/client.py)
# NOTE: Warmup reduces first-request latency by pre-loading the model
VLLM_WARMUP_ENABLED=true                     # Enable warmup request on connection
VLLM_WARMUP_MAX_TOKENS=10                    # Warmup request output tokens (keep small)

# ===============================================================================
# 10. PATTERN SYSTEM CONFIGURATION (8 variables)
# ===============================================================================
# Pattern Loader Configuration (from src/utils/pattern_loader.py)
# NOTE: Pattern system caches compiled regex patterns for 79 YAML files
PATTERN_CACHE_SIZE=1000                      # Pattern cache size (LRU cache for compiled patterns)
PATTERN_MAX_WORKERS=4                        # Max parallel pattern loading threads (ThreadPoolExecutor)
PATTERN_ENABLE_CACHING=true                  # Enable pattern caching (recommended for performance)
PATTERN_CACHE_TTL=3600                       # Pattern cache TTL in seconds (1 hour)
PATTERN_LAZY_LOADING=false                   # Enable lazy pattern loading (load on-demand vs. startup)
PATTERN_VALIDATE_ON_LOAD=true                # Validate regex patterns during load (catches errors early)
PATTERN_AUTO_RELOAD=false                    # Auto-reload patterns on YAML file changes (dev mode only)
PATTERN_COMPRESSION_ENABLED=false            # Enable pattern compression in cache (trades CPU for memory)

# ===============================================================================
# 11. REGEX ENGINE CONFIGURATION (5 variables)
# ===============================================================================
# Regex Compilation and Execution Settings
# NOTE: Controls Python re module behavior across 79 pattern files
REGEX_CACHE_SIZE=500                         # Compiled regex cache size (Python re module cache)
REGEX_TIMEOUT_MS=1000                        # Regex execution timeout in milliseconds (prevents catastrophic backtracking)
REGEX_ENABLE_MULTILINE=true                  # Enable multiline mode by default (^ and $ match line boundaries)
REGEX_ENABLE_DOTALL=false                    # Enable dotall mode by default (. matches newlines)
REGEX_MAX_RECURSION_DEPTH=100                # Maximum regex recursion depth (for nested groups)

# ===============================================================================
# 12. PERFORMANCE & MODEL TUNING (20 variables)
# ===============================================================================
# Multi-Pass Extraction Configuration
# NOTE: Multi-pass strategy extracts entities in 8 specialized passes
MULTIPASS_MAX_ITERATIONS=8                   # Maximum multi-pass iterations (currently: PARTIES, COURTS, LEGAL_REFS, etc.)
MULTIPASS_CONVERGENCE_THRESHOLD=0.95         # Stop when confidence reaches this threshold (0.0-1.0)
MULTIPASS_ENABLE_PARALLEL=true               # Enable parallel pass execution (faster but uses more memory)
MULTIPASS_BATCH_SIZE=10                      # Batch size for parallel passes
MULTIPASS_TIMEOUT_PER_PASS=300               # Timeout per pass in seconds (5 minutes)

# Entity Deduplication Configuration
# NOTE: Deduplication prevents duplicate entities across passes
DEDUP_SIMILARITY_THRESHOLD=0.85              # Entity similarity threshold (0.0-1.0, fuzzy matching)
DEDUP_ALGORITHM=fuzzy                        # Deduplication algorithm (fuzzy|exact|semantic)
DEDUP_PRESERVE_HIGHEST_CONFIDENCE=true       # Keep highest confidence duplicate
DEDUP_CROSS_TYPE_DEDUP=false                 # Deduplicate across entity types (e.g., PERSON vs. ATTORNEY)

# Response Parsing & Validation
# NOTE: JSON response parsing from vLLM can fail - these settings control repair behavior
RESPONSE_PARSER_STRICT_MODE=false            # Strict JSON parsing mode (reject malformed JSON)
RESPONSE_PARSER_AUTO_REPAIR=true             # Auto-repair malformed JSON (strip markdown, fix braces)
RESPONSE_PARSER_MAX_REPAIR_ATTEMPTS=3        # Maximum JSON repair attempts before failing
RESPONSE_VALIDATION_SCHEMA_STRICT=false      # Strict Pydantic schema validation (reject on schema mismatch)

# Model-Specific Tuning
# NOTE: Context window management for 128K token model
MODEL_CONTEXT_WINDOW_BUFFER=1000             # Reserve buffer tokens for context (safety margin)
MODEL_OUTPUT_TOKEN_BUFFER=500                # Reserve buffer tokens for output (safety margin)
MODEL_ENABLE_DYNAMIC_BATCHING=true           # Enable dynamic batching in vLLM
MODEL_BATCH_TIMEOUT_MS=100                   # Dynamic batch timeout in milliseconds

# Extraction Quality Controls
# NOTE: Quality filters applied post-extraction
QUALITY_MIN_ENTITY_CONFIDENCE=0.5            # Minimum entity confidence to keep (0.0-1.0)
QUALITY_ENABLE_CONFIDENCE_CALIBRATION=true   # Enable confidence calibration (adjust raw scores)
QUALITY_REJECT_PARTIAL_MATCHES=false         # Reject partial entity matches (e.g., "John" from "John Smith")

# ===============================================================================
# 13. HEALTH CHECK CONFIGURATION (11 variables)
# ===============================================================================
# NOTE: Health monitoring and readiness check configuration
HEALTH__ENABLE_HEALTH_CHECKS=true            # Enable health monitoring and checks
HEALTH__HEALTH_CHECK_INTERVAL_SECONDS=30     # Health check interval (seconds)
HEALTH__HEALTH_CHECK_TIMEOUT_SECONDS=5       # Health check timeout (seconds)
HEALTH__CHECK_PATTERN_LOADER=true            # Check pattern loader health (pattern system availability)
HEALTH__CHECK_AI_SERVICES=true               # Check AI service connectivity (vLLM availability)
HEALTH__CHECK_DATABASE_CONNECTION=true       # Check database connectivity (Supabase health)
HEALTH__CHECK_MEMORY_USAGE=true              # Monitor memory usage and report in health checks
HEALTH__MEMORY_WARNING_THRESHOLD_PERCENT=80.0  # Memory warning threshold (percentage, 0-100)
HEALTH__MEMORY_CRITICAL_THRESHOLD_PERCENT=95.0 # Memory critical threshold (percentage, 0-100)
HEALTH__EXTRACTION_LATENCY_WARNING_MS=5000   # Extraction latency warning threshold (milliseconds)
HEALTH__EXTRACTION_LATENCY_CRITICAL_MS=15000 # Extraction latency critical threshold (milliseconds)

# ===============================================================================
# 14. PERFORMANCE MONITORING (10 variables)
# ===============================================================================
# NOTE: Performance metrics collection and monitoring configuration
PERFORMANCE__ENABLE_PERFORMANCE_MONITORING=true  # Enable comprehensive performance monitoring
PERFORMANCE__PERFORMANCE_SAMPLE_RATE=0.1     # Performance sampling rate (0.0-1.0, 0.1 = 10% of requests)
PERFORMANCE__ENABLE_METRICS_EXPORT=true      # Enable metrics export to monitoring systems
PERFORMANCE__MAX_MEMORY_USAGE_MB=2048        # Maximum memory usage limit (MB, 2GB)
PERFORMANCE__MEMORY_CHECK_INTERVAL_SECONDS=60  # Memory check interval (seconds)
PERFORMANCE__ENABLE_MEMORY_CLEANUP=true      # Enable automatic memory cleanup and garbage collection
PERFORMANCE__MAX_WORKER_THREADS=10           # Maximum worker threads for concurrent operations
PERFORMANCE__THREAD_POOL_SIZE=8              # Thread pool size for parallel processing
PERFORMANCE__RESULT_CACHE_SIZE=1000          # Result cache size (number of cached results)
PERFORMANCE__RESULT_CACHE_TTL_SECONDS=1800   # Result cache TTL (seconds, 30 minutes)

# ===============================================================================
# TOTAL: 161 VARIABLES (Updated from 119)
# ===============================================================================
# Service Configuration: 10 (+3: debug, secret_key, security settings)
# Logging Configuration: 14 (NEW SECTION)
# Database - Supabase: 6 (+2: store_results, retention)
# vLLM Direct Integration: 7 (+2: context similarity, max examples)
# Core Extraction Settings: 9
# Chunking Configuration: 9
# Service URLs: 7
# Performance & Resource Management: 6
# Security: 3
# vLLM Advanced Configuration: 30
# Pattern System Configuration: 10 (+2: auto-reload settings)
# Regex Engine Configuration: 5
# Performance & Model Tuning: 20
# Health Check Configuration: 11 (NEW SECTION)
# Performance Monitoring: 10 (NEW SECTION)
# ===============================================================================
#
# MIGRATION FROM v2.0.0:
# - YAML configuration (config/settings.yaml) is DEPRECATED
# - All settings now managed through .env (161 variables)
# - New sections: Logging (14 vars), Health Checks (11 vars), Performance Monitoring (10 vars)
# - See docs/MIGRATION_GUIDE_v2.0.1.md for detailed migration instructions
# ===============================================================================
#
# CONFIGURATION GUIDE:
#
# 1. REQUIRED CHANGES (Before First Run):
#    - SUPABASE_URL, SUPABASE_KEY, SUPABASE_API_KEY, SUPABASE_SERVICE_KEY
#    - SERVICE_URL (replace YOUR_SERVER_IP with actual IP)
#    - AI_EXTRACTION_VLLM_URL (replace YOUR_SERVER_IP)
#    - All SERVICE_URLs in section 6 (replace YOUR_SERVER_IP)
#    - JWT_SECRET (generate secure random string)
#
# 2. RECOMMENDED TUNING (After Initial Deployment):
#    - VLLM_GPU_MEMORY_UTILIZATION: Increase to 0.95 if no OOM errors
#    - VLLM_MAX_NUM_BATCHED_TOKENS: Increase to 16384 for higher throughput
#    - MULTIPASS_ENABLE_PARALLEL: Disable if memory constrained
#    - PATTERN_CACHE_SIZE: Increase to 2000 for production workloads
#
# 3. PERFORMANCE OPTIMIZATION (For Production):
#    - VLLM_ENABLE_PREFIX_CACHING: Keep true for legal document workloads
#    - CACHE_ENABLED: Keep true, tune CACHE_TTL_EXTRACTION based on update frequency
#    - MAX_CONCURRENT_EXTRACTIONS: Tune based on GPU memory and CPU cores
#    - VLLM_PREFILL_RATE/DECODE_RATE: Measure actual rates with your GPU
#
# 4. DEBUGGING (Development Only):
#    - DEBUG_MODE: Set to true
#    - LOG_LEVEL: Set to DEBUG
#    - VLLM_ENFORCE_EAGER: Set to true (disables CUDA graphs for easier debugging)
#    - RESPONSE_PARSER_STRICT_MODE: Set to true (fail fast on malformed JSON)
#
# ===============================================================================
